{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# THIS IS THE REAL EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quick fix : 14, 71~81\n",
    "#### quick fix 2 : find best tr cases and only include them in ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --quiet torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet nibabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(inputs, targets, smooth=0.001):\n",
    "    # Smooth prevents miss matches from being too significant but keeps the child of fraction above zero.\n",
    "    # from torch.nn import functional as F\n",
    "    # inputs = F.sigmoid(inputs) # uncomment if inputs is not between 0-1\n",
    "\n",
    "    inputs = inputs.flatten()\n",
    "    targets = targets.flatten()\n",
    "\n",
    "    intersection = (inputs * targets).sum()\n",
    "    dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "    # return 1 - dice\n",
    "    # return -torch.log(dice)\n",
    "    return dice\n",
    "\n",
    "def eval2(input, gt, smooth=0.00001):\n",
    "    intersect = np.sum(np.logical_and(input, gt))\n",
    "    union = np.sum(np.logical_or(input, gt))\n",
    "    dice = (2. * intersect + smooth) / (union + intersect + smooth)\n",
    "    return np.round(dice, 4)\n",
    "\n",
    "def ensemble(pred_2d, pred_3d):\n",
    "    from torch.nn import functional as F\n",
    "    # INPUTS ARE PROBABILITIES MATRICES\n",
    "    fn_class =  lambda x: 1.0 * (x > 0.5) # network output image를 binary class로 분류해주는 class function정의\n",
    "    # compare tensors and return bigger num\n",
    "    # compare = lambda x, y : 0 if x > y else 1\n",
    "    \n",
    "    # pred_2d = F.softmax(pred_2d)\n",
    "    # pred_3d = F.softmax(pred_3d)\n",
    "\n",
    "    # twoD = compare(pred_2d[0].transpose(1,2,0), pred_2d[1].transpose(1,2,0))\n",
    "    # threeD = compare(pred_3d[0].transpose(1,2,0), pred_3d[1].transpose(1,2,0))\n",
    "\n",
    "    pred_2d_flatten = pred_2d.flatten()\n",
    "    pred_3d_flatten = pred_3d.flatten()\n",
    "\n",
    "    new_pred = (pred_2d_flatten * pred_3d_flatten)/2\n",
    "    new_label = fn_class(new_pred)\n",
    "\n",
    "    return new_label\n",
    "\n",
    "def init_imgs(path): # PACK UP PATHS\n",
    "    pred2d_list = os.listdir(os.path.join(path, \"pred2d\"))\n",
    "    pred3d_list = os.listdir(os.path.join(path, \"pred3d\"))\n",
    "    gt_list = os.listdir(os.path.join(path, \"b4_raw\"))\n",
    "    \n",
    "    temp_list = []\n",
    "    for thing in pred2d_list:\n",
    "        if \".nii.gz\" in thing:\n",
    "            mpath = os.path.join(path, \"pred2d\")\n",
    "            temp_list.append(os.path.join(mpath, thing))\n",
    "    pred2d_list = temp_list\n",
    "    \n",
    "    temp_list = []\n",
    "    for thing in pred3d_list:\n",
    "        if \".nii.gz\" in thing:\n",
    "            mpath = os.path.join(path, \"pred3d\")\n",
    "            temp_list.append(os.path.join(mpath, thing))\n",
    "    pred3d_list = temp_list\n",
    "\n",
    "    pnum_list = [os.path.basename(file).split(\".nii.gz\")[0] for file in pred3d_list]\n",
    "\n",
    "    temp_list = []\n",
    "    for p in gt_list:\n",
    "        if p in pnum_list:\n",
    "            seg = os.path.join(path, f\"b4_raw/{p}/b4_reg_seg.nii.gz\")\n",
    "            temp_list.append(seg)\n",
    "    gt_list = temp_list\n",
    "\n",
    "    temp_list = [gt_list, pred2d_list, pred3d_list]\n",
    "\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/dwseon/dat/\"\n",
    "l = init_imgs(path)\n",
    "gt_list = l[0]\n",
    "pred2d_list = l[1]\n",
    "pred3d_list = l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len check : (19, 0, 19)\n"
     ]
    }
   ],
   "source": [
    "print (f\"Len check : {len(gt_list), len(pred2d_list), len(pred3d_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### \"Data supplement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 'data supplement'\n",
    "indiv_dice = {}\n",
    "for i, gt in enumerate(gt_list):\n",
    "    pNum = os.path.basename(gt.split(\"/b4_reg_seg.nii.gz\")[0])\n",
    "    gt_img = nib.load(gt).get_fdata().astype(int)\n",
    "    #gt_img = torch.from_numpy(gt_img)\n",
    "    for threeD in pred3d_list:\n",
    "        pNum3D = os.path.basename(threeD).split(\".nii.gz\")[0]\n",
    "        if pNum == pNum3D:\n",
    "            img_3d = nib.load(threeD).get_fdata().astype(int)\n",
    "            #img_3d = torch.from_numpy(img_3d)\n",
    "            indiv_dice[pNum3D] = eval(img_3d, gt_img, smooth=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testcase 082: 4.9999750001249995e-06\n",
      "Testcase 083: 1.0\n",
      "Testcase 084: 1.0\n",
      "Testcase 085: 0.7888198790555919\n",
      "Testcase 086: 3.412969166792862e-08\n",
      "Testcase 087: 0.4678899326655994\n",
      "Testcase 088: 1.0\n",
      "Testcase 089: 1.0\n",
      "Testcase 090: 1.0\n",
      "Testcase 091: 1.0\n",
      "Testcase 092: 1.0\n",
      "Testcase 093: 1.0\n",
      "Testcase 094: 1.0\n",
      "Testcase 095: 1.0\n",
      "Testcase 096: 1.0\n",
      "Testcase 097: 1.0\n",
      "Testcase 098: 1.0\n",
      "Testcase 099: 1.0\n",
      "Testcase 100: 0.40650411329234853\n",
      "score zero count at 0\n",
      "score one count at 70\n",
      "above median 86\n"
     ]
    }
   ],
   "source": [
    "test = [\"082\", \"083\", \"084\", \"085\", \"086\", \"087\", \"088\", \"089\", \"090\", \"091\", \"092\", \"093\", \"094\", \"095\", \"096\", \"097\", \"098\", \"099\", \"100\"]\n",
    "d = []\n",
    "zero = 0\n",
    "one = 0\n",
    "above_hf = 0\n",
    "for key, val in indiv_dice.items():\n",
    "    if val > 0 and val < 1:\n",
    "        d.append((key, val))\n",
    "        if key in test:\n",
    "            print(f\"Testcase {key}: {val}\")\n",
    "    if val == 0: \n",
    "        zero += 1\n",
    "        if key in test:\n",
    "            print(f\"Testcase {key}: {val}\")\n",
    "    elif val == 1: \n",
    "        one += 1\n",
    "        if key in test:\n",
    "            print(f\"Testcase {key}: {val}\")\n",
    "    if val > 0.5: above_hf +=1\n",
    "print(f\"score zero count at {zero}\\nscore one count at {one}\\nabove median {above_hf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('086', 3.412969166792862e-08),\n",
       " ('066', 2.777777006173054e-07),\n",
       " ('005', 4.1666649305562796e-07),\n",
       " ('051', 3.3333222222592593e-06),\n",
       " ('004', 3.3333222222592593e-06),\n",
       " ('049', 3.3333222222592593e-06),\n",
       " ('082', 4.9999750001249995e-06),\n",
       " ('070', 9.99990000099999e-06),\n",
       " ('081', 9.99990000099999e-06),\n",
       " ('026', 0.19741101622312274),\n",
       " ('077', 0.24338628341871518),\n",
       " ('100', 0.40650411329234853),\n",
       " ('023', 0.46153887573932634),\n",
       " ('087', 0.4678899326655994),\n",
       " ('030', 0.5080583307132899),\n",
       " ('075', 0.5547918563677968),\n",
       " ('014', 0.6589469875843944),\n",
       " ('032', 0.7021276701373167),\n",
       " ('013', 0.7363323743867413),\n",
       " ('085', 0.7888198790555919),\n",
       " ('072', 0.8192771193206555),\n",
       " ('035', 0.829931975681429),\n",
       " ('068', 0.8299319766455334),\n",
       " ('058', 0.8481375401679788),\n",
       " ('007', 0.8607595112962644),\n",
       " ('057', 0.8744588771762147),\n",
       " ('019', 0.8774193627471379),\n",
       " ('010', 0.9375000097656235),\n",
       " ('011', 0.9444444598765389),\n",
       " ('078', 0.948115784008106)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"len: {len(d)}\\ndice max: {np.max(d)}\\ndice min: {np.min(d)}\\ndice unique: {set(d)}\")\n",
    "for i in range(len(d)):\n",
    "    for j in range(len(d)):\n",
    "        if d[j][1] > d[i][1]:\n",
    "            temp = d[i]\n",
    "            d[i] = d[j]\n",
    "            d[j] = temp\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Supplement\" ends\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeD_dice = {}\n",
    "twoD_dice = {}\n",
    "ensemble_dice = {}\n",
    "prob2d, prob3d = 0, 0\n",
    "ensem_out = os.path.join(path, \"ensemble\")\n",
    "if not os.path.isdir(ensem_out):\n",
    "    os.makedirs(ensem_out)\n",
    "for i, gt in enumerate(gt_list):\n",
    "    gt_np = nib.load(gt).get_fdata().astype(int)\n",
    "    gt_img = torch.from_numpy(gt_np)\n",
    "    for twoD in pred2d_list:\n",
    "        if os.path.basename(gt.split(\"/b4_reg_seg.nii.gz\")[0]) == os.path.basename(twoD).split(\".nii.gz\")[0]:\n",
    "            # LOAD IMAGE\n",
    "            pred2d_img = nib.load(twoD).get_fdata().astype(int)\n",
    "            ev2 = eval2(pred2d_img, gt_np)\n",
    "            pred2d_img = torch.from_numpy(pred2d_img)\n",
    "            base = os.path.basename(twoD).split(\".nii.gz\")[0]\n",
    "            # DICE\n",
    "            twoD_dice[base] = (eval(pred2d_img, gt_img, smooth=0.00001), ev2)\n",
    "            # SOFTMAX\n",
    "            # prob2d = np.load(os.path.join(path, f\"pred2d/{base}.npz\"), allow_pickle=True)[\"softmax\"] # this has 2 channels tho\n",
    "    for threeD in pred3d_list:\n",
    "        if os.path.basename(gt.split(\"/b4_reg_seg.nii.gz\")[0]) == os.path.basename(threeD).split(\".nii.gz\")[0]:\n",
    "            # LOAD IMAGE\n",
    "            \n",
    "            pred3d_img = nib.load(threeD).get_fdata().astype(int)\n",
    "            ev2 = eval2(pred3d_img, gt_np)\n",
    "            pred3d_img = torch.from_numpy(pred3d_img)\n",
    "            base = os.path.basename(threeD).split(\".nii.gz\")[0]\n",
    "            # DICE\n",
    "            threeD_dice[base] = (eval(pred3d_img, gt_img, smooth=0.00001), ev2)\n",
    "            # SORFTMAX\n",
    "            # prob3d = np.load(os.path.join(path, f\"pred3d/{base}.npz\"), allow_pickle=True)[\"softmax\"] # so let's use them separately\n",
    "    # ENSEMBLE\n",
    "    # ens_res = ensemble(prob2d, prob3d) # assuming [0] is pred and [1] is gt\n",
    "    # ens_nii = nib.Nifti1Image(ens_res.reshape(prob2d[1].transpose(1,2,0).shape), affine=np.eye(4))\n",
    "    # nib.save(ens_nii, os.path.join(ensem_out, f\"{base}.nii.gz\"))\n",
    "    # ensemble_dice[base] = eval(torch.from_numpy(ens_res.astype(int)), gt_img, smooth=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_dice(dic):\n",
    "    tot = 0\n",
    "    for thing in dic:\n",
    "        tot += dic[thing][0]\n",
    "    if len(dic) != 0:\n",
    "        tot = tot / len(dic)\n",
    "    else:\n",
    "        tot = \"This plan contains 0 data.\"\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of \n",
      "- 2d dice: This plan contains 0 data.\n",
      "- 3d dice: 0.9459847807884216\n",
      "- Ensemble: This plan contains 0 data.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average of \\n- 2d dice: {avg_dice(twoD_dice)}\\n- 3d dice: {avg_dice(threeD_dice)}\\n- Ensemble: {avg_dice(ensemble_dice)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Rate and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as kungfu\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/dwseon/dat/pred3d/007.nii.gz\n",
      "/workspace/dwseon/dat/b4_raw/032/b4_reg_seg.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(pred3d_list[0])\n",
    "print(gt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/dwseon/dat/pred3d/007.nii.gz'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inspect = 1\n",
    "for i in range(len(pred3d_list)):\n",
    "    pred = nib.load(pred3d_list[i])\n",
    "    gt = nib.load(gt_list[i])\n",
    "\n",
    "    if i >= n_inspect:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "BELOW ARE TEST CELLS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(os.path.join(path, \"pred2d/087.nii.gz\")).get_fdata().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39845888])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.flatten()\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.load(\"/workspace/dwseon/dat/pred2d/087.pkl\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024, 38)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = aa[\"softmax\"][0].transpose(1,2,0)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape don't matter but the len\n",
    "data = aa['softmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 38, 1024, 1024)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
