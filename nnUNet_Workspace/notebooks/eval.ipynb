{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# THIS IS THE REAL EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --quiet torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(inputs, targets, smooth=0.001):\n",
    "    # Smooth prevents miss matches from being too significant but keeps the child of fraction above zero.\n",
    "    # from torch.nn import functional as F\n",
    "    # inputs = F.sigmoid(inputs) # uncomment if inputs is not between 0-1\n",
    "\n",
    "    inputs = inputs.flatten()\n",
    "    targets = targets.flatten()\n",
    "\n",
    "    intersection = (inputs * targets).sum()\n",
    "    dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "    # return 1 - dice\n",
    "    # return -torch.log(dice)\n",
    "    return dice\n",
    "\n",
    "def ensemble(pred_2d, pred_3d):\n",
    "    from torch.nn import functional as F\n",
    "    # INPUTS ARE PROBABILITIES MATRICES\n",
    "    fn_class =  lambda x: 1.0 * (x > 0.5) # network output image를 binary class로 분류해주는 class function정의\n",
    "    # compare tensors and return bigger num\n",
    "    # compare = lambda x, y : 0 if x > y else 1\n",
    "    \n",
    "    # pred_2d = F.softmax(pred_2d)\n",
    "    # pred_3d = F.softmax(pred_3d)\n",
    "\n",
    "    # twoD = compare(pred_2d[0].transpose(1,2,0), pred_2d[1].transpose(1,2,0))\n",
    "    # threeD = compare(pred_3d[0].transpose(1,2,0), pred_3d[1].transpose(1,2,0))\n",
    "\n",
    "    pred_2d_flatten = pred_2d.flatten()\n",
    "    pred_3d_flatten = pred_3d.flatten()\n",
    "\n",
    "    new_pred = (pred_2d_flatten * pred_3d_flatten)/2\n",
    "    new_label = fn_class(new_pred)\n",
    "\n",
    "    return new_label\n",
    "\n",
    "def init_imgs(path): # PACK UP PATHS\n",
    "    pred2d_list = os.listdir(os.path.join(path, \"pred2d\"))\n",
    "    pred3d_list = os.listdir(os.path.join(path, \"pred3d\"))\n",
    "    gt_list = os.listdir(os.path.join(path, \"b4_raw\"))\n",
    "    \n",
    "    temp_list = []\n",
    "    for thing in pred2d_list:\n",
    "        if \".nii.gz\" in thing:\n",
    "            mpath = os.path.join(path, \"pred2d\")\n",
    "            temp_list.append(os.path.join(mpath, thing))\n",
    "    pred2d_list = temp_list\n",
    "    \n",
    "    temp_list = []\n",
    "    for thing in pred3d_list:\n",
    "        if \".nii.gz\" in thing:\n",
    "            mpath = os.path.join(path, \"pred3d\")\n",
    "            temp_list.append(os.path.join(mpath, thing))\n",
    "    pred3d_list = temp_list\n",
    "\n",
    "    pnum_list = [os.path.basename(file).split(\".nii.gz\")[0] for file in pred3d_list]\n",
    "\n",
    "    temp_list = []\n",
    "    for p in gt_list:\n",
    "        if p in pnum_list:\n",
    "            seg = os.path.join(path, f\"b4_raw/{p}/b4_reg_seg.nii.gz\")\n",
    "            temp_list.append(seg)\n",
    "    gt_list = temp_list\n",
    "\n",
    "    temp_list = [gt_list, pred2d_list, pred3d_list]\n",
    "\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/dwseon/dat/\"\n",
    "l = init_imgs(path)\n",
    "gt_list = l[0]\n",
    "pred2d_list = l[1]\n",
    "pred3d_list = l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len check : (19, 0, 19)\n"
     ]
    }
   ],
   "source": [
    "print (f\"Len check : {len(gt_list), len(pred2d_list), len(pred3d_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeD_dice = {}\n",
    "twoD_dice = {}\n",
    "ensemble_dice = {}\n",
    "prob2d, prob3d = 0, 0\n",
    "ensem_out = os.path.join(path, \"ensemble\")\n",
    "if not os.path.isdir(ensem_out):\n",
    "    os.makedirs(ensem_out)\n",
    "for i, gt in enumerate(gt_list):\n",
    "    gt_img = nib.load(gt).get_fdata().astype(int)\n",
    "    gt_img = torch.from_numpy(gt_img)\n",
    "    for twoD in pred2d_list:\n",
    "        if os.path.basename(gt.split(\"/b4_reg_seg.nii.gz\")[0]) == os.path.basename(twoD).split(\".nii.gz\")[0]:\n",
    "            # LOAD IMAGE\n",
    "            pred2d_img = nib.load(twoD).get_fdata().astype(int)\n",
    "            pred2d_img = torch.from_numpy(pred2d_img)\n",
    "            base = os.path.basename(twoD).split(\".nii.gz\")[0]\n",
    "            # DICE\n",
    "            twoD_dice[base] = eval(pred2d_img, gt_img, smooth=0.00001)\n",
    "            # SOFTMAX\n",
    "            # prob2d = np.load(os.path.join(path, f\"pred2d/{base}.npz\"), allow_pickle=True)[\"softmax\"] # this has 2 channels tho\n",
    "    for threeD in pred3d_list:\n",
    "        if os.path.basename(gt.split(\"/b4_reg_seg.nii.gz\")[0]) == os.path.basename(threeD).split(\".nii.gz\")[0]:\n",
    "            # LOAD IMAGE\n",
    "            \n",
    "            pred3d_img = nib.load(threeD).get_fdata().astype(int)\n",
    "            pred3d_img = torch.from_numpy(pred3d_img)\n",
    "            base = os.path.basename(threeD).split(\".nii.gz\")[0]\n",
    "            # DICE\n",
    "            threeD_dice[base] = eval(pred3d_img, gt_img, smooth=0.00001)\n",
    "            # SORFTMAX\n",
    "            # prob3d = np.load(os.path.join(path, f\"pred3d/{base}.npz\"), allow_pickle=True)[\"softmax\"] # so let's use them separately\n",
    "    # ENSEMBLE\n",
    "    # ens_res = ensemble(prob2d, prob3d) # assuming [0] is pred and [1] is gt\n",
    "    # ens_nii = nib.Nifti1Image(ens_res.reshape(prob2d[1].transpose(1,2,0).shape), affine=np.eye(4))\n",
    "    # nib.save(ens_nii, os.path.join(ensem_out, f\"{base}.nii.gz\"))\n",
    "    # ensemble_dice[base] = eval(torch.from_numpy(ens_res.astype(int)), gt_img, smooth=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_dice(dic):\n",
    "    tot = 0\n",
    "    for thing in dic:\n",
    "        tot += dic[thing]\n",
    "    if len(dic) != 0:\n",
    "        tot = tot / len(dic)\n",
    "    else:\n",
    "        tot = \"This plan contains 0 data.\"\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of \n",
      "- 2d dice: This plan contains 0 data.\n",
      "- 3d dice: 0.8243799209594727\n",
      "- Ensemble: This plan contains 0 data.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average of \\n- 2d dice: {avg_dice(twoD_dice)}\\n- 3d dice: {avg_dice(threeD_dice)}\\n- Ensemble: {avg_dice(ensemble_dice)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "BELOW ARE TEST CELLS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(os.path.join(path, \"pred2d/087.nii.gz\")).get_fdata().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39845888])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.flatten()\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.load(\"/workspace/dwseon/dat/pred2d/087.pkl\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024, 38)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = aa[\"softmax\"][0].transpose(1,2,0)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape don't matter but the len\n",
    "data = aa['softmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 38, 1024, 1024)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
